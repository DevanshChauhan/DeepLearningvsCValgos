{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2965251,
          "sourceType": "datasetVersion",
          "datasetId": 1817999
        }
      ],
      "dockerImageVersionId": 30698,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "Renmfeegk72b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Define the directory containing the training data\n",
        "train_dir = '/kaggle/input/vegetable-image-dataset/Vegetable Images/train'\n",
        "\n",
        "# Initialize lists to store images and their corresponding labels\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Iterate through each class folder\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_dir = os.path.join(train_dir, class_name)\n",
        "\n",
        "    # Iterate through each image file in the class folder\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "\n",
        "        # Load and preprocess the image\n",
        "        img = image.load_img(img_path, target_size=(224, 224))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_tensor = tf.convert_to_tensor(img_array)\n",
        "\n",
        "        # Append the image tensor and its label to the lists\n",
        "        images.append(img_tensor)\n",
        "        labels.append(class_name)\n",
        "\n",
        "# Convert the lists to TensorFlow tensors\n",
        "images_tensor = tf.stack(images)\n",
        "labels_tensor = tf.constant(labels)\n",
        "\n",
        "# Display the shape of the tensors\n",
        "print(\"Images tensor shape:\", images_tensor.shape)\n",
        "print(\"Labels tensor shape:\", labels_tensor.shape)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:15:03.759266Z",
          "iopub.execute_input": "2024-05-10T20:15:03.760535Z",
          "iopub.status.idle": "2024-05-10T20:16:39.383823Z",
          "shell.execute_reply.started": "2024-05-10T20:15:03.760491Z",
          "shell.execute_reply": "2024-05-10T20:16:39.382643Z"
        },
        "trusted": true,
        "id": "mCu9PJiPk72d",
        "outputId": "a75f8ec3-9aa0-4bba-9793-62ff5d694d09"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "2024-05-10 20:15:05.714748: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-10 20:15:05.714953: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-10 20:15:05.862420: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Images tensor shape: (15000, 224, 224, 3)\nLabels tensor shape: (15000,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import cv2\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "sift = cv2.SIFT_create()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:17:38.405949Z",
          "iopub.execute_input": "2024-05-10T20:17:38.406802Z",
          "iopub.status.idle": "2024-05-10T20:17:39.364810Z",
          "shell.execute_reply.started": "2024-05-10T20:17:38.406764Z",
          "shell.execute_reply": "2024-05-10T20:17:39.363646Z"
        },
        "trusted": true,
        "id": "rbavGpxyk72e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def getSIFT(img):\n",
        "    '''\n",
        "        @description Get the SIFT features of the input image\n",
        "        @param img -> np.array: |img| => { (32, 32, 3) }\n",
        "        @return descriptor -> np.array n x 128\n",
        "    '''\n",
        "    # Convert the image to grayscale\n",
        "    #gray_image = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2GRAY)\n",
        "    # Convert the image to unsigned 8-bit integer format\n",
        "    img_uint8 = img.numpy().astype(np.uint8)\n",
        "\n",
        "    # Convert the image to grayscale\n",
        "    gray_image = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "\n",
        "    kps, des = sift.detectAndCompute(gray_image, None)\n",
        "    return des if des is not None else np.array([]).reshape(0, 128)\n",
        "descriptors_list = []\n",
        "\n",
        "# Iterate over each image array\n",
        "for img_array in images_tensor:\n",
        "    descriptors = getSIFT(img_array)\n",
        "    descriptors_list.append(descriptors)\n",
        "\n",
        "# Convert the list of descriptors to a single NumPy array\n",
        "descriptors_array = np.vstack(descriptors_list)\n",
        "\n",
        "# Print the shape of the descriptors array\n",
        "print(\"Shape of descriptors array:\", descriptors_array.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:17:42.476544Z",
          "iopub.execute_input": "2024-05-10T20:17:42.476968Z",
          "iopub.status.idle": "2024-05-10T20:22:28.889525Z",
          "shell.execute_reply.started": "2024-05-10T20:17:42.476912Z",
          "shell.execute_reply": "2024-05-10T20:22:28.885980Z"
        },
        "trusted": true,
        "id": "NWZ4K6U_k72e",
        "outputId": "54fbef3c-030f-4c1a-8669-9816618ac043"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Shape of descriptors array: (5735598, 128)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MiniBatchKMeans\n",
        "def create_codebook(features, num_clusters, batch_size):\n",
        "    # Create a MiniBatchKMeans clustering object\n",
        "    kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=batch_size, random_state=0)\n",
        "    #kmeans = MiniBatchKMeans(n_clusters=num_clusters, batch_size=batch_size, init_size=3*num_clusters, max_iter=100, tol=0.001, random_state=0)\n",
        "\n",
        "\n",
        "    # Fit the clustering model to the SIFT features\n",
        "    kmeans.fit(features)\n",
        "\n",
        "    return kmeans\n",
        "#Number of clusters for codebook\n",
        "num_clusters = 50\n",
        "# Batch size for MiniBatchKMeans\n",
        "batch_size = 1000\n",
        "\n",
        "# Create the codebook\n",
        "codebook = create_codebook(descriptors_array, num_clusters, batch_size)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:22:40.841716Z",
          "iopub.execute_input": "2024-05-10T20:22:40.842343Z",
          "iopub.status.idle": "2024-05-10T20:22:49.790345Z",
          "shell.execute_reply.started": "2024-05-10T20:22:40.842312Z",
          "shell.execute_reply": "2024-05-10T20:22:49.789462Z"
        },
        "trusted": true,
        "id": "LB3oWPp7k72e",
        "outputId": "52ddbfd9-b476-44d6-d8ec-92d9c2517620"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 3 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def compute_bovw_representation(features, codebook):\n",
        "    num_clusters = codebook.n_clusters\n",
        "    bovw_representation = []\n",
        "\n",
        "    for image_features in features:\n",
        "        if len(image_features) > 0:\n",
        "            # Assign each feature to a cluster\n",
        "            cluster_assignments = codebook.predict(image_features)\n",
        "\n",
        "            # Create a histogram of cluster frequencies\n",
        "            histogram = np.bincount(cluster_assignments, minlength=num_clusters)\n",
        "\n",
        "            # Normalize the histogram\n",
        "            histogram = histogram / np.sum(histogram)\n",
        "\n",
        "            bovw_representation.append(histogram)\n",
        "        else:\n",
        "            # Handle cases where no features were detected\n",
        "            bovw_representation.append(np.zeros(num_clusters))\n",
        "\n",
        "    return bovw_representation\n",
        "\n",
        "# Compute BoVW representation for features using the codebook\n",
        "bovw_representation = compute_bovw_representation(descriptors_list, codebook)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:22:59.341514Z",
          "iopub.execute_input": "2024-05-10T20:22:59.342331Z",
          "iopub.status.idle": "2024-05-10T20:23:06.930702Z",
          "shell.execute_reply.started": "2024-05-10T20:22:59.342291Z",
          "shell.execute_reply": "2024-05-10T20:23:06.929639Z"
        },
        "trusted": true,
        "id": "OnNpcOItk72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "def train_knn_classifier(train_bovw_features, train_labels):\n",
        "    # Create a k-NN classifier object\n",
        "    knn_classifier = KNeighborsClassifier(n_neighbors=5, algorithm='brute')\n",
        "\n",
        "    # Fit the classifier on the training data\n",
        "    knn_classifier.fit(train_bovw_features, train_labels)\n",
        "\n",
        "    return knn_classifier\n",
        "# Train k-NN classifier\n",
        "label_encoder_np = labels_tensor.numpy()\n",
        "knn_classifier = train_knn_classifier(bovw_representation, labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:23:13.177764Z",
          "iopub.execute_input": "2024-05-10T20:23:13.178577Z",
          "iopub.status.idle": "2024-05-10T20:23:13.207800Z",
          "shell.execute_reply.started": "2024-05-10T20:23:13.178540Z",
          "shell.execute_reply": "2024-05-10T20:23:13.206818Z"
        },
        "trusted": true,
        "id": "BLcUyvpFk72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del images_tensor\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:23:30.541539Z",
          "iopub.execute_input": "2024-05-10T20:23:30.542003Z",
          "iopub.status.idle": "2024-05-10T20:23:30.548135Z",
          "shell.execute_reply.started": "2024-05-10T20:23:30.541965Z",
          "shell.execute_reply": "2024-05-10T20:23:30.546992Z"
        },
        "trusted": true,
        "id": "TPdyu1RSk72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del descriptors_array"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:24:17.392503Z",
          "iopub.execute_input": "2024-05-10T20:24:17.393757Z",
          "iopub.status.idle": "2024-05-10T20:24:17.407767Z",
          "shell.execute_reply.started": "2024-05-10T20:24:17.393711Z",
          "shell.execute_reply": "2024-05-10T20:24:17.406604Z"
        },
        "trusted": true,
        "id": "ZzbgzYGhk72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the directory containing the test data\n",
        "test_dir = '/kaggle/input/vegetable-image-dataset/Vegetable Images/test'\n",
        "\n",
        "# Initialize lists to store test images and their corresponding labels\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Iterate through each class folder in the test directory\n",
        "for class_name in os.listdir(test_dir):\n",
        "    class_dir = os.path.join(test_dir, class_name)\n",
        "\n",
        "    # Iterate through each image file in the class folder\n",
        "    for img_name in os.listdir(class_dir):\n",
        "        img_path = os.path.join(class_dir, img_name)\n",
        "\n",
        "        # Load and preprocess the test image\n",
        "        test_img = image.load_img(img_path, target_size=(224, 224))\n",
        "        test_img_array = image.img_to_array(test_img)\n",
        "        test_img_tensor = tf.convert_to_tensor(test_img_array)\n",
        "\n",
        "        # Append the test image tensor and its label to the lists\n",
        "        test_images.append(test_img_tensor)\n",
        "        test_labels.append(class_name)\n",
        "\n",
        "# Convert the lists of test images and labels to TensorFlow tensors\n",
        "test_images_tensor = tf.stack(test_images)\n",
        "test_labels_tensor = tf.constant(test_labels)\n",
        "\n",
        "# Display the shape of the test tensors\n",
        "print(\"Test Images tensor shape:\", test_images_tensor.shape)\n",
        "print(\"Test Labels tensor shape:\", test_labels_tensor.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:25:19.581837Z",
          "iopub.execute_input": "2024-05-10T20:25:19.582316Z",
          "iopub.status.idle": "2024-05-10T20:25:39.419715Z",
          "shell.execute_reply.started": "2024-05-10T20:25:19.582282Z",
          "shell.execute_reply": "2024-05-10T20:25:39.417816Z"
        },
        "trusted": true,
        "id": "iMjGimt3k72f",
        "outputId": "4fc6b348-4c86-418b-9e43-dc831f308d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test Images tensor shape: (3000, 224, 224, 3)\nTest Labels tensor shape: (3000,)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_descriptors_list = []\n",
        "#test_image_arrays = [test_image_tensor.numpy() for test_image_tensor in test_cifar100_data]\n",
        "# Iterate over each image array\n",
        "for img_array in test_images_tensor:\n",
        "    # Check if the shape of the image array is (3, 32, 32)\n",
        "    # if img_array.shape == (3, 32, 32):\n",
        "    #     # Convert the image array to the correct data type and dimensions\n",
        "    #     #img_array = img_array.transpose((1, 2, 0))  # Transpose to (32, 32, 3) format\n",
        "    #     # Get the SIFT descriptors for the image\n",
        "    #     img_array = image_arrays[i].transpose((1, 2, 0))\n",
        "    #     img_array = (img_array - img_array.min()) / (img_array.max() - img_array.min())  # Normalize pixel values\n",
        "    #     img_array = np.uint8(img_array * 255)\n",
        "    test_descriptors = getSIFT(img_array)\n",
        "        # Append the descriptors to the list\n",
        "    test_descriptors_list.append(test_descriptors)\n",
        "\n",
        "# Convert the list of descriptors to a single NumPy array\n",
        "test_descriptors_array = np.vstack(test_descriptors_list)\n",
        "\n",
        "# Print the shape of the descriptors array\n",
        "print(\"Shape of descriptors array:\", test_descriptors_array.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:27:25.459829Z",
          "iopub.execute_input": "2024-05-10T20:27:25.460847Z",
          "iopub.status.idle": "2024-05-10T20:28:23.449483Z",
          "shell.execute_reply.started": "2024-05-10T20:27:25.460799Z",
          "shell.execute_reply": "2024-05-10T20:28:23.448273Z"
        },
        "trusted": true,
        "id": "kw1wOKgCk72g",
        "outputId": "af8c85bd-2c0b-41d5-9cd9-1442c607c500"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Shape of descriptors array: (1173792, 128)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def evaluate_classifier(classifier, test_bovw_features, train_labels, test_labels):\n",
        "    # Find nearest neighbors for test data\n",
        "    distances, indices = classifier.kneighbors(test_bovw_features)\n",
        "\n",
        "    # Evaluate the classifier\n",
        "    predictions = []\n",
        "\n",
        "    for neighbors in indices:\n",
        "        if len(neighbors) > 0:\n",
        "            neighbor_labels = train_labels[neighbors]\n",
        "            most_common_label = np.bincount(neighbor_labels).argmax()\n",
        "            predictions.append(most_common_label)\n",
        "        else:\n",
        "            # Handle cases where no neighbors were found\n",
        "            predictions.append(-1)\n",
        "\n",
        "    # Filter out test samples without predictions (-1)\n",
        "    filtered_test_labels = []\n",
        "    filtered_predictions = []\n",
        "\n",
        "    for i, prediction in enumerate(predictions):\n",
        "        if prediction != -1:\n",
        "            filtered_test_labels.append(test_labels[i])\n",
        "            filtered_predictions.append(prediction)\n",
        "\n",
        "    # Calculate accuracy and generate a classification report\n",
        "    accuracy = accuracy_score(filtered_test_labels, filtered_predictions)\n",
        "    report = classification_report(filtered_test_labels, filtered_predictions)\n",
        "\n",
        "    return accuracy, report\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:30:08.375812Z",
          "iopub.execute_input": "2024-05-10T20:30:08.376251Z",
          "iopub.status.idle": "2024-05-10T20:30:08.385435Z",
          "shell.execute_reply.started": "2024-05-10T20:30:08.376215Z",
          "shell.execute_reply": "2024-05-10T20:30:08.384165Z"
        },
        "trusted": true,
        "id": "SJnaEkNTk72g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Assuming you have features and labels for training and testing\n",
        "# features_train, labels_train = ...\n",
        "# features_test, labels_test = ...\n",
        "\n",
        "# Initialize the Naive Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "\n",
        "# Train the classifier\n",
        "nb_classifier.fit(bovw_representation, labels)\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = nb_classifier.predict(test_bovw_features)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "report = classification_report(test_labels, predictions)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:35:20.913229Z",
          "iopub.execute_input": "2024-05-10T20:35:20.913676Z",
          "iopub.status.idle": "2024-05-10T20:35:21.021566Z",
          "shell.execute_reply.started": "2024-05-10T20:35:20.913643Z",
          "shell.execute_reply": "2024-05-10T20:35:21.020219Z"
        },
        "trusted": true,
        "id": "wonhpFUfk72g",
        "outputId": "ae4cc94e-401f-4503-e119-d41bae51b006"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.5103333333333333\nClassification Report:\n               precision    recall  f1-score   support\n\n        Bean       0.59      0.24      0.34       200\nBitter_Gourd       0.60      0.70      0.65       200\nBottle_Gourd       0.58      0.49      0.53       200\n     Brinjal       0.38      0.28      0.32       200\n    Broccoli       0.60      0.78      0.68       200\n     Cabbage       0.31      0.61      0.41       200\n    Capsicum       0.64      0.49      0.56       200\n      Carrot       0.34      0.19      0.24       200\n Cauliflower       0.69      0.80      0.74       200\n    Cucumber       0.45      0.58      0.51       200\n      Papaya       0.44      0.50      0.47       200\n      Potato       0.45      0.46      0.46       200\n     Pumpkin       0.52      0.81      0.63       200\n      Radish       0.64      0.37      0.47       200\n      Tomato       0.67      0.35      0.46       200\n\n    accuracy                           0.51      3000\n   macro avg       0.53      0.51      0.50      3000\nweighted avg       0.53      0.51      0.50      3000\n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "def train_logistic_regression(train_bovw_features, train_labels):\n",
        "    # Create a Logistic Regression classifier object\n",
        "    logistic_classifier = LogisticRegression(n_jobs=1, max_iter=3000)\n",
        "    # Fit the classifier on the training data\n",
        "    logistic_classifier.fit(train_bovw_features, train_labels)\n",
        "\n",
        "    return logistic_classifier\n",
        "\n",
        "lr_classifier = train_logistic_regression(bovw_representation, labels)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:39:59.932802Z",
          "iopub.execute_input": "2024-05-10T20:39:59.933641Z",
          "iopub.status.idle": "2024-05-10T20:40:01.612266Z",
          "shell.execute_reply.started": "2024-05-10T20:39:59.933599Z",
          "shell.execute_reply": "2024-05-10T20:40:01.611015Z"
        },
        "trusted": true,
        "id": "JwoyNB-kk72g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "def evaluate_classifier2(classifier, test_bovw_features, test_labels):\n",
        "    # Predict labels for test data\n",
        "    predictions = classifier.predict(test_bovw_features)\n",
        "\n",
        "    # Calculate accuracy and generate a classification report\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "    report = classification_report(test_labels, predictions)\n",
        "\n",
        "    return accuracy, report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:41:04.708163Z",
          "iopub.execute_input": "2024-05-10T20:41:04.709077Z",
          "iopub.status.idle": "2024-05-10T20:41:04.717069Z",
          "shell.execute_reply.started": "2024-05-10T20:41:04.709032Z",
          "shell.execute_reply": "2024-05-10T20:41:04.715989Z"
        },
        "trusted": true,
        "id": "kDLufMSEk72g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, report = evaluate_classifier2(lr_classifier, test_bovw_features, test_labels)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Classification Report:\")\n",
        "print(report)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-10T20:41:07.383074Z",
          "iopub.execute_input": "2024-05-10T20:41:07.383457Z",
          "iopub.status.idle": "2024-05-10T20:41:07.478151Z",
          "shell.execute_reply.started": "2024-05-10T20:41:07.383429Z",
          "shell.execute_reply": "2024-05-10T20:41:07.477035Z"
        },
        "trusted": true,
        "id": "IWRoYZdJk72g",
        "outputId": "00c07a48-364e-4451-bf1f-5b2ef598b1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Accuracy: 0.5346666666666666\nClassification Report:\n              precision    recall  f1-score   support\n\n        Bean       0.67      0.49      0.57       200\nBitter_Gourd       0.58      0.71      0.64       200\nBottle_Gourd       0.65      0.34      0.45       200\n     Brinjal       0.42      0.13      0.20       200\n    Broccoli       0.49      0.80      0.61       200\n     Cabbage       0.47      0.45      0.46       200\n    Capsicum       0.54      0.45      0.49       200\n      Carrot       0.50      0.41      0.45       200\n Cauliflower       0.55      0.84      0.67       200\n    Cucumber       0.60      0.56      0.58       200\n      Papaya       0.54      0.35      0.43       200\n      Potato       0.42      0.46      0.44       200\n     Pumpkin       0.54      0.71      0.62       200\n      Radish       0.52      0.73      0.61       200\n      Tomato       0.55      0.59      0.57       200\n\n    accuracy                           0.53      3000\n   macro avg       0.54      0.53      0.52      3000\nweighted avg       0.54      0.53      0.52      3000\n\n",
          "output_type": "stream"
        }
      ]
    }
  ]
}